{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import concat, col, lit, split, to_date, date_format, row_number\n",
        "from pyspark.sql.window import Window\n",
        "import os\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Load the config file\n",
        "with open('/content/drive/MyDrive/project/config.json') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# Check if the input_csv file exists and is in csv format\n",
        "if 'input_csv' not in config or not config['input_csv'].endswith('.csv') or not os.path.exists(config['input_csv']):\n",
        "    print(\"No CSV file is selected or the file is invalid.\")\n",
        "    exit()\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = spark.read.csv(config['input_csv'], header=True, inferSchema=True)\n",
        "df2 = spark.read.csv(config['input2_csv'], header=True, inferSchema=True)\n",
        "\n",
        "# Convert the DataFrame to a Parquet file\n",
        "df.write.mode(\"overwrite\").parquet('temp.parquet')\n",
        "df2.write.mode(\"overwrite\").parquet('temp2.parquet')\n",
        "\n",
        "# Load the DataFrames from the Parquet files\n",
        "df = spark.read.parquet('temp.parquet')\n",
        "df2 = spark.read.parquet('temp2.parquet')\n",
        "\n",
        "# Apply transformations\n",
        "for transformation in config['transformations']:\n",
        "    if transformation['type'] == 'date_format':\n",
        "        df = df.withColumn(transformation['column'], to_date(col(transformation['column']), transformation['input_format']))\n",
        "        df = df.withColumn(transformation['column'], date_format(col(transformation['column']), transformation['output_format']))\n",
        "    elif transformation['type'] == 'concat':\n",
        "        df = df.withColumn(transformation['output_column'], concat(*[col(c) for c in transformation['columns']], lit(transformation['separator'])))\n",
        "    elif transformation['type'] == 'split':\n",
        "        split_col = split(df[transformation['column']], transformation['separator'])\n",
        "        for i, output_column in enumerate(transformation['output_columns']):\n",
        "            df = df.withColumn(output_column, split_col.getItem(i))\n",
        "    elif transformation['type'] == 'drop':\n",
        "        df = df.drop(transformation['column'])\n",
        "\n",
        "# Join the 'Industry' column from temp2.parquet with the DataFrame\n",
        "if 'Industry' in df2.columns and 'sno' in df.columns:\n",
        "    joined_df = df.join(df2.select('Industry', 'sno'), on='sno', how='inner')\n",
        "\n",
        "# Save the transformed DataFrame to a new Parquet file\n",
        "joined_df.write.mode('overwrite').parquet(config['output_parquet'])\n",
        "\n",
        "# Read the final transformed DataFrame\n",
        "final_df = spark.read.parquet(config['output_parquet'])\n",
        "\n",
        "# Create a new DataFrame with aligned 'sno' values\n",
        "final_df = final_df.withColumn('sno', row_number().over(Window.orderBy(\"sno\")).cast(\"integer\"))\n",
        "\n",
        "# Display the DataFrame with aligned sno values\n",
        "final_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMf-hQ6n7GXp",
        "outputId": "a8f14eea-0df2-4db3-fd16-cfd139982f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------------+---------+------+--------------------+--------------------+-------------+--------------------+-----+---+----+--------------------+\n",
            "|sno|        User Id|Last Name|   Sex|               Email|               Phone|Date of birth|           Job Title|Month|Day|Year|            Industry|\n",
            "+---+---------------+---------+------+--------------------+--------------------+-------------+--------------------+-----+---+----+--------------------+\n",
            "|  1|4defE49671cF860|  Shannon|  Male|   tvang@example.net|   574-440-1423x9799|   2020-07-09|    Technical brewer| 2020| 07|  09|              Sports|\n",
            "|  2|F89B87bCf8f210b|      Lin|  Male| helen14@example.net|001-273-664-2268x...|   1909-06-20|Teacher, adult ed...| 1909| 06|  20|      Legal Services|\n",
            "|  3|Cad6052BDd5DEaf|    Blake|Female| brent05@example.org|  927-880-5785x85266|   1964-08-19|Armed forces oper...| 1964| 08|  19|         Hospitality|\n",
            "|  4|e83E46f80f629CD|  Hoffman|Female|munozcraig@exampl...|001-147-429-8340x608|   2009-02-19|         Ship broker| 2009| 02|  19|     Food Production|\n",
            "|  5|60AAc4DcaBcE3b6|   Campos|Female|brownevelyn@examp...|        166-126-4390|   1997-10-02|       Media planner| 1997| 10|  02| Computer Networking|\n",
            "|  6|7ACb92d81A42fdf|    Patel|  Male|muellerjoel@examp...|001-379-612-1298x853|   2021-04-07| Engineer, materials| 2021| 04|  07|Aviation / Aerospace|\n",
            "|  7|A00bacC18101d37| Castillo|Female|billmoody@example...| (448)494-0852x63243|   1975-04-09|Historic building...| 1975| 04|  09|         Hospitality|\n",
            "|  8|B012698Cf31cfec|  Cochran|  Male| glenn94@example.org|          4425100065|   1966-07-19|    Engineer, mining| 1966| 07|  19|            Printing|\n",
            "|  9|a5bd11BD7dA1a4B|  Richard|Female|   blane@example.org|   352.362.4148x8344|   2021-09-02|  Wellsite geologist| 2021| 09|  02|Primary / Seconda...|\n",
            "| 10|9540a6df05eF6cf|   Bailey|  Male|pittmanterrence@e...|  (629)632-4570x1832|   1963-05-13|    Graphic designer| 1963| 05|  13|  Building Materials|\n",
            "| 11|f967B4EcdF6B227|   Norton|  Male| acannon@example.net| (164)034-4347x22022|   2009-08-19|     Engineer, water| 2009| 08|  19| Airlines / Aviation|\n",
            "| 12|326C83BbeC1BCFd|     Lara|Female|davilacassidy@exa...| +1-915-351-2636x083|   1962-03-29|     Product manager| 1962| 03|  29|              Design|\n",
            "| 13|d9dfB09F01e16EB|  Sanders|Female|brucejoanna@examp...|001-931-852-5157x...|   1912-07-12|        Web designer| 1912| 07|  12|          Automotive|\n",
            "| 14|1E5b00F6AC95FD8|   Dorsey|Female|  xcrane@example.net|        266-633-2107|   1988-04-19|           Homeopath| 1988| 04|  19|International Tra...|\n",
            "| 15|1cfc2eDd75cfB01|      Ali|  Male|lawrenceluke@exam...|+1-204-855-1654x3158|   1952-04-16|Scientist, audiol...| 1952| 04|  16|Aviation / Aerospace|\n",
            "| 16|c85FcEDF4D7dCA5|  Wheeler|  Male|xmontgomery@examp...|   044-808-5012x5663|   1912-08-13|Manufacturing sys...| 1912| 08|  13|             Fishery|\n",
            "| 17|AD2Cd35dCaeD2AB|     Hart|  Male| blittle@example.net|  712-978-1974x94056|   1939-02-16|Race relations of...| 1939| 02|  16|Alternative Medicine|\n",
            "| 18|Ca217c22e3fEf2c| Shepherd|Female| ralph98@example.com|+1-324-844-1260x2...|   1911-08-29|       Administrator| 1911| 08|  29|Religious Institu...|\n",
            "| 19|DDFea9C0D3b8Bda|     Todd|  Male|zhenderson@exampl...|   664-084-9864x4425|   2011-12-24|Armed forces oper...| 2011| 12|  24|   Apparel / Fashion|\n",
            "| 20|eeed253bcc5d02F|  Skinner|Female| paula37@example.com|   026-376-9429x6935|   1916-10-15|Psychologist, cou...| 1916| 10|  15|               Music|\n",
            "+---+---------------+---------+------+--------------------+--------------------+-------------+--------------------+-----+---+----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}